{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:17:56.941744Z",
     "start_time": "2020-07-16T17:17:56.938751Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as npt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:17:57.524826Z",
     "start_time": "2020-07-16T17:17:57.505878Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_default = pd.read_csv('data/Default.csv', index_col=0)\n",
    "\n",
    "tb_default['default_binary'] = tb_default['default'].apply(\n",
    "    lambda x: 1 if x == \"Yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:17:58.079783Z",
     "start_time": "2020-07-16T17:17:58.069783Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_default.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:27:10.880516Z",
     "start_time": "2020-07-16T17:27:10.330926Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=tb_default,\n",
    "                x='balance',\n",
    "                y='income',\n",
    "                hue='default',\n",
    "                palette='tab10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:30:01.045043Z",
     "start_time": "2020-07-16T17:30:00.831107Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "sns.boxplot(data=tb_default, x='default', y='balance', ax=ax[0])\n",
    "sns.boxplot(data=tb_default, x='default', y='income', ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:32:04.750332Z",
     "start_time": "2020-07-16T17:32:04.657609Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=tb_default, x='balance', y='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:33:16.270717Z",
     "start_time": "2020-07-16T17:33:16.196877Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X=tb_default[['balance']], y=tb_default['default_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:34:21.768925Z",
     "start_time": "2020-07-16T17:34:21.762941Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_default['pred_lmfit'] = lr.predict(tb_default[['balance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:34:25.768756Z",
     "start_time": "2020-07-16T17:34:25.763769Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_default['pred_lmfit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:36:03.335731Z",
     "start_time": "2020-07-16T17:36:01.797984Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=tb_default, x='balance', y='default_binary', alpha = 0.5)\n",
    "sns.lineplot(data=tb_default, x='balance', y='pred_lmfit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predictions may be out of range.\n",
    "- But yeah, the predictions will be ordered.\n",
    "- Problem is - this approach cannot be extended to qualitative responses containing more than two levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than predicting the `target` directly, `logistic regression` tries to model the <b>`probability`</b> that your `target` belongs to a particular category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:42:44.458712Z",
     "start_time": "2020-07-16T17:42:43.657912Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "sns.regplot(data=tb_default,\n",
    "            x='balance',\n",
    "            y='default_binary',\n",
    "            color='blue',\n",
    "            ax=ax[0])\n",
    "sns.regplot(data=tb_default,\n",
    "            x='balance',\n",
    "            y='default_binary',\n",
    "            logistic=True,\n",
    "            color='blue',\n",
    "            ci=None,\n",
    "            ax=ax[1])\n",
    "\n",
    "ax[0].set_title('Linear Regression')\n",
    "ax[1].set_title('Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S-shaped curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{e^{x}}{(1+e^{x})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:54:27.831972Z",
     "start_time": "2020-07-16T17:54:27.728713Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10, 10, 0.13)\n",
    "\n",
    "plt.plot(x, np.exp(2*x)/(1 + np.exp(2*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Linear Regression\n",
    "If we were to use a linear regression, the equation would be:\n",
    "\n",
    "$$ y = P(default=Yes | balance) = a_0 + a_1\\cdot balance $$\n",
    "\n",
    "## Logistic Regression\n",
    "The logistic regression seeks to model the probability in a better way:\n",
    "\n",
    "$$ P(default=Yes | balance) = \\frac{e^{a_0 + a_1\\cdot x}}{1 + e^{a_0 + a_1\\cdot x}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:57:29.135500Z",
     "start_time": "2020-07-16T17:57:29.126527Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:58:13.863882Z",
     "start_time": "2020-07-16T17:58:13.831880Z"
    }
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X=tb_default[['balance']], y=tb_default['default_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.predict_proba(tb_default[['balance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_default['pred_prob'] = logistic.predict_proba(tb_default[['balance']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:59:02.013828Z",
     "start_time": "2020-07-16T17:59:02.008843Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_default['default_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = tb_default, x = 'balance', y = 'pred_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como fazemos para ter uma previsão categórica, como nossa variável resposta? Utilizamos o conceito de **threshold**: utilizamos um valor de probabilidade pelo qual dividiremos as previsões - abaixo deste valor todas as previsões serão `False` acima, `True`.\n",
    "\n",
    "Para classificação binária esse threshold é tipicamente 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_default['pred_binary_where'] = np.where(tb_default['pred_prob'] > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T17:58:51.988791Z",
     "start_time": "2020-07-16T17:58:51.984801Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_default['pred_binary'] = logistic.predict(tb_default[['balance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tb_default['pred_binary_where'] == tb_default['pred_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = tb_default, x = 'balance', y = 'pred_prob')\n",
    "sns.scatterplot(data = tb_default, x = 'balance', y = 'pred_binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medindo o erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_default['erro_binario'] = np.where(\n",
    "    tb_default['pred_binary'] == tb_default['default_binary'], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tb_default['erro_binario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum(tb_default['erro_binario'])/len(tb_default['erro_binario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic.score(tb_default[['balance']], tb_default['default_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_default.groupby(['default_binary'])['erro_binario'].agg(['sum', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **acurácia** é uma métrica simples, direta e fácil de se explicar. No entanto, muitas vezes ela não é suficiente para comparar/avaliar modelos:\n",
    "\n",
    "* Em problemas onde o **tamanho das duas classes é muito diferente** ela oculta a taxa de erro na classe minoritaria.\n",
    "* Muitas vezes o **custo** de um falso positivo e um falso negativo não são equivalentes. No exemplo acima o custo de deixar de emprestar (custo de oportunidade) pode ser muito diferente do custo de calote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos extender a avaliação de erro do modelo atrvés de **outras métricas** de erro que tratem dos diferentes problemas levantados acima. Primeiro, vamos analisar a curva ROC para entender melhor o trade-off que ocorre quando mudamos o threshold de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_erro = tb_default.groupby(['default_binary'])['erro_binario'].agg(['sum', 'count']).reset_index()\n",
    "tb_erro.columns = ['valor_verdadeiro', 'erros', 'total']\n",
    "tb_erro['acertos'] = tb_erro['total'] - tb_erro['erros']\n",
    "tb_erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *taxa de positivos verdadeiros* (TPR, recall ou sensibilidade) é **100/333**, ou seja, o número de positivos que o modelo previu **corretamente** dividido pelo número de positivos total.\n",
    "\n",
    "A *taxa de falsos positivos* (FPR ou fall-out) é **233/333**, ou seja, o número de positivos que o modelo previu **incorretamente** dividido pelo número de positivos total.\n",
    "\n",
    "Existe um trade-off entre TPR e FPR: conforme aumento o threshold diminuo a FPR mas aumento a TPR (e vice-versa). A forma mais simples de visualizar este trade-off é através da curva ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true = tb_default['default_binary'],\n",
    "                                 y_score = tb_default['pred_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax[0].plot(thresholds, tpr)\n",
    "ax[0].set_title('Curva de TPR (Recall)')\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_xlabel('Threshold')\n",
    "ax[0].set_ylabel('TPR')\n",
    "ax[1].plot(thresholds, fpr)\n",
    "ax[1].set_title('Curva de FPR')\n",
    "ax[1].set_xlim([0, 1])\n",
    "ax[1].set_ylabel('FPR')\n",
    "fig.suptitle('Curva de FPR/TPR por Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "ax.plot(fpr, tpr, label = 'Modelo')\n",
    "ax.plot(fpr, fpr, label = 'Aleatório')\n",
    "ax.set_xlabel('FPR - Taxa de Positivos Falsos')\n",
    "ax.set_ylabel('TPR - Taxa de Positivos Verdadeiros (Recall)')\n",
    "ax.set_aspect('equal')\n",
    "plt.legend()\n",
    "fig.suptitle('Curva ROC (Receiver Operating Characteristic)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_score = roc_auc_score(y_true=tb_default['default_binary'],\n",
    "              y_score=tb_default['pred_prob'])\n",
    "print(f\"Área debaixo da Curva ROC: {round(roc_score, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora a curva ROC represente bem o impacto que a mudança de threshold tem sobre o erro de classificação ainda temos um problema: o desbalanceamento das classes. Assim como a acurácia, a curva ROC dá peso demais para as classificações negativas corretas (classe majoritaria), ocultando o erro sobre a classificação positiva (classe minoritaria)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para consolidar a nossa avaliação do erro de previsão, precisamos ver ainda outra métrica, que lida melhor com problemas desbalanceados - a precisão. A precisão é a taxa entre o número de positivos verdadeiros e o número de positivos previstos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_confusion = tb_default.groupby(['default_binary', 'pred_binary'])['pred_prob'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_confusion.pivot_table(columns='pred_binary', index='default_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true = tb_default['default_binary'],\n",
    "                 y_pred = tb_default['pred_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 100/(42 + 100)\n",
    "recall = 100/(100+233)\n",
    "print(f\"Precisão: {precision} - Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc, rec, thresh = precision_recall_curve(y_true=tb_default['default_binary'],\n",
    "                                          probas_pred=tb_default['pred_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax[0].plot(thresh, prc[:-1])\n",
    "ax[0].set_title('Curva de Precisão')\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_xlabel('Threshold')\n",
    "ax[0].set_ylabel('Precisão')\n",
    "ax[1].plot(thresh, rec[:-1])\n",
    "ax[1].set_title('Curva de Recall (TPR)')\n",
    "ax[1].set_xlim([0, 1])\n",
    "ax[1].set_xlabel('Threshold')\n",
    "ax[1].set_ylabel('Recall (TPR)')\n",
    "fig.suptitle('Curva de FPR/TPR por Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "ax.plot(rec, prc)\n",
    "ax.set_title('Curva de R-P (Recall-Precision)')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_xlabel('Recall (TPR)')\n",
    "ax.set_ylabel('Precisão')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 * (precision * recall)/(precision + recall)\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_true = tb_default['default_binary'],\n",
    "             y_pred = tb_default['pred_binary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acurácia\n",
    "\n",
    "**PROS**\n",
    "\n",
    "* Fácil de explicar/entender;\n",
    "* Medida direta, conversa diretamente com o que as pessoas imaginam ser o *erro do modelo*.\n",
    "\n",
    "**CONTRAS**\n",
    "\n",
    "* Não representa bem o erro em problemas de classes desbalanceadas.\n",
    "\n",
    "**QUANDO USAR**\n",
    "\n",
    "* Apenas em problemas balanceados;\n",
    "* Quando as classes previstas não tem custo diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusão\n",
    "\n",
    "**PROS**\n",
    "\n",
    "* Fácil de explicar/entender;\n",
    "* Permite a visualização de todos os erros do modelo.\n",
    "\n",
    "**CONTRAS**\n",
    "\n",
    "* Não é um indicador;\n",
    "* Não permite a avaliação automatica de modelos.\n",
    "\n",
    "**QUANDO USAR**\n",
    "\n",
    "* Na fase exploratória de modelagem, para comparar diferentes versões iniciais do modelo. Sempre que estamos construindo os modelos manualmente e podemos analisar o resultado de cada um particularmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC-ROC (e Curva ROC)\n",
    "\n",
    "**PROS**\n",
    "\n",
    "* A curva ROC é uma boa representação do trade-off entre precisão e falsos positivos;\n",
    "* O AUC-ROC score não é específico para um threshold, permitindo uma avaliação do score (a probabilidade prevista) do modelo.\n",
    "\n",
    "**CONTRAS**\n",
    "\n",
    "* O AUC-ROC score não representa bem o erro em problemas de classes desbalanceadas.\n",
    "\n",
    "**QUANDO USAR**\n",
    "\n",
    "* Na fase exploratória de modelagem, para comparar diferentes versões iniciais do modelo. Sempre que estamos construindo os modelos manualmente e podemos analisar o resultado de cada um particularmente;\n",
    "* Em problemas de classes balanceadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-SCORE\n",
    "\n",
    "**PROS**\n",
    "\n",
    "* A medida padrão dentro da área de modelagem/ciência de dados. Qualquer outro analista/cientista de dados vai entender o que você está falando;\n",
    "* A utilização da precisão torna o F1 um bom método para medir o erro em problemas desbalanceados.\n",
    "\n",
    "**CONTRAS**\n",
    "\n",
    "* Difícil de explicar (fora de *0 é ruim 1 é bom*)\n",
    "\n",
    "**QUANDO USAR**\n",
    "\n",
    "* Para comparar 2 ou mais modelos quantitativamente;\n",
    "* Durante métodos de seleção de variáveis/técnicas automáticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, assim como na regressão, vamos normalizar as variáveis de entrada para termos uma interpretação do intercepto mais natural:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(tb_default[['balance']])\n",
    "y = tb_default['default_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fit = LogisticRegression()\n",
    "log_fit.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro o intercepto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Intercepto: {log_fit.intercept_[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que isso significa?? Precisamos lembrar que a regressão logística projeta o logaritmo das chances (o chamado logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T15:57:54.804994Z",
     "start_time": "2020-04-23T15:57:54.800007Z"
    }
   },
   "source": [
    "$$ P(default) = \\frac{e^{a_0 + a_1\\cdot x}}{1 + e^{a_0 + a_1\\cdot x}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left(\\frac{P(default)}{1 - P(default)}\\right) = e^{a_0 + a_1\\cdot x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(log_fit.intercept_[0])*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponenciar o intercepto nos dá a **chance** (p/(1-p), não a probabilidade p) média de default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepto = np.exp(log_fit.intercept_[0])*1000\n",
    "print(f\"Chance de default em com balance médio: {round(intercepto,2)}:1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depois os coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Coeficiente Balance: {log_fit.coef_[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(log_fit.coef_[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O coeficiente nos diz o quanto a variação de uma unidade de X impacta, multiplicativamente, a **chance** (de novo, não a probabilidade) de default. No caso acima vemos que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impacto_1x = np.exp(log_fit.coef_[0][0])\n",
    "print(f\"Chance de default em +1 desvio padrão de X: {round(impacto_1x * intercepto,2)}:1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Problema de Chances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema das interpretações acima é que, a não ser que trabalhemos em uma casa de apostas, **chances não são facilmente interpretáveis**. Uma solução é criar um gráfico mostrando o **impacto da variação de X sobre a PROBABILIDADE**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impacto_x = np.linspace(-2, 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds = np.exp(log_fit.intercept_[0] + impacto_x * log_fit.coef_[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fit.coef_[0][0]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = (odds/(1+odds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_simul = pd.DataFrame({\n",
    "    'impacto_x': impacto_x,\n",
    "    'odds': odds,\n",
    "    'prob': probabilities\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = tb_simul, x = 'impacto_x', y = 'prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_default['X'] = scaler.fit_transform(tb_default[['balance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_default['pred_prob'] = log_fit.predict_proba(tb_default[['X']])[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = tb_default, x = 'X', y = 'pred_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo com mais coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(tb_default[['balance', 'income']])\n",
    "y = tb_default['default_binary']\n",
    "log_fit2 = LogisticRegression()\n",
    "log_fit2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impacto_bal = np.linspace(-4, 4, 100)\n",
    "odds = np.exp(log_fit2.intercept_[0] + impacto_bal * log_fit2.coef_[0][0])\n",
    "probabilities = (odds/(1+odds))\n",
    "tb_simul = pd.DataFrame({\n",
    "    'impacto_bal': impacto_bal,\n",
    "    'odds': odds,\n",
    "    'prob': probabilities\n",
    "})\n",
    "sns.scatterplot(data = tb_simul, x = 'impacto_bal', y = 'prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impacto_inc = np.linspace(-4, 4, 100)\n",
    "odds = np.exp(log_fit2.intercept_[0] + impacto_inc * log_fit2.coef_[0][1])\n",
    "probabilities = (odds/(1+odds))\n",
    "tb_simul = pd.DataFrame({\n",
    "    'impacto_inc': impacto_inc,\n",
    "    'odds': odds,\n",
    "    'prob': probabilities\n",
    "})\n",
    "sns.scatterplot(data = tb_simul, x = 'impacto_inc', y = 'prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EXTRA - The Loss function of the Logistic Regression\n",
    "\n",
    "What does the logistic regression tries to minimize? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Intuitively, we want to assign more punishment when predicting 1 while the actual is 0 and when predict 0 while the actual is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\begin{equation}\n",
    "  Cost(\\hat{p}, y_{obs}) =\n",
    "    \\begin{cases}\n",
    "      -log(\\hat{p}) & \\text{if } y_{obs} = 1  \\\\\n",
    "      -log(1-\\hat{p}) & \\text{if } y_{obs} = 0\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$Cost(\\hat{p}, y_{obs}) = -y_{obs} \\cdot log(\\hat{p}) - (1 - y_{obs})\\cdot log(1-\\hat{p})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$\\hat{p}$ is my estimated probability, and $y_{obs}$ is the label of my observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So let's understand what this `cost function` represents:\n",
    "- Imagine I have an observation whose true default label is 0 ($y_{obs}$ = 0) and my model predicts that the probability of its value being 1 (default) is 80%. We would have:\n",
    "    \n",
    "    - $cost(0.8, 0) = -0 \\cdot log(0.8) - 1 \\cdot log(1-0.8) = -log(0.2) \\approx 1.6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now if we say that the probability of it being 1 is 90%:\n",
    "- $cost(0.9, 0) = -0 \\cdot log(0.9) - 1 \\cdot log(1-0.9) = -log(0.1) \\approx 2.3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T04:50:40.653499Z",
     "start_time": "2020-04-24T04:50:40.648511Z"
    },
    "hidden": true
   },
   "source": [
    "Now if we say that the probability of it being 1 is 95%:\n",
    "- $cost(0.95, 0) = -0 \\cdot log(0.95) - 1 \\cdot log(1-0.95) = -log(0.05) \\approx 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T18:51:22.909209Z",
     "start_time": "2020-07-16T18:51:22.454426Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize=(12,4))\n",
    "y_obs = 0\n",
    "p = np.arange(0.01, 1, 0.01)\n",
    "cost = -y_obs * np.log(p) - (1-y_obs) * np.log(1-p)\n",
    "ax[0].plot(p, cost)\n",
    "\n",
    "y_obs = 1\n",
    "p = np.arange(0.01, 1, 0.01)\n",
    "cost = -y_obs * np.log(p) - (1-y_obs) * np.log(1-p)\n",
    "ax[1].plot(p, cost)\n",
    "\n",
    "ax[0].set_title('$y_{true}$ = 0')\n",
    "ax[1].set_title('$y_{true}$ = 1')\n",
    "\n",
    "ax[0].set_ylabel('Cost')\n",
    "\n",
    "ax[0].set_xlabel('Probability of y = 1')\n",
    "ax[1].set_xlabel('Probability of y = 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Thus, it penalizes when you are sure it is one, but you are wrong. Or it penalizes when you are sure it is zero, but you are wrong, the true label is one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So this is what logistic regression tries to minimize. Two important summaries:\n",
    "\n",
    "- The results of the logistic regression are <b>probabilities</b> of being the label 1.\n",
    "- As it minimizes that cost function, <b>you can be very confident of observations predicted with probabilities close to 1 or close to 0</b>. They will probably not be wrong because your model tried to avoid it during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Odds - the chances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T15:57:54.804994Z",
     "start_time": "2020-04-23T15:57:54.800007Z"
    },
    "hidden": true
   },
   "source": [
    "$$ P(default) = \\frac{e^{a_0 + a_1\\cdot x}}{1 + e^{a_0 + a_1\\cdot x}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$ \\left(\\frac{P(default)}{1 - P(default)}\\right) = e^{a_0 + a_1\\cdot x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T19:38:34.295034Z",
     "start_time": "2020-04-23T19:38:34.290056Z"
    },
    "hidden": true
   },
   "source": [
    "1 in 5 people is a fraudster.\n",
    "\n",
    "P = 1/5 = 0.2\n",
    "\n",
    "Odds = $\\frac{0.2}{0.8} = 1/4 = 0.25$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T19:40:36.109308Z",
     "start_time": "2020-04-23T19:40:36.105294Z"
    },
    "hidden": true
   },
   "source": [
    "Odds: $\\frac{\\text{favorable events}}{\\text{unfavorable events}}$, Probability: $\\frac{\\text{favorable events}}{\\text{total events}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Log Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$ log\\left(\\frac{P(default)}{1 - P(default)}\\right) = a_0 + a_1x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Remember that for **Linear Regression**, the value a_1, the coefficient, can be understood as how much of our target change if we change 1 unit in `x`. That is, if we change 1 in `x`, our target changes by $a_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For **Logistic Regression**, though, increasing X by one unit affects the **log odds** in $a_1$. So, although increasing `x` indeed increases the probability P, the value it will increase depends on X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "303px",
    "width": "214px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
