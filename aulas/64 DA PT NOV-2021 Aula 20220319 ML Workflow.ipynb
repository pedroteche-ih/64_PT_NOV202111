{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:05.257363Z",
     "start_time": "2022-03-19T12:55:03.682497Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:05.273304Z",
     "start_time": "2022-03-19T12:55:05.259337Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Strategy\n",
    "\n",
    "The validation strategy is one of the most important steps in machine learning. If one fails to effectivelly validate your machine learning model, the results may be unexpectedly bad.\n",
    "\n",
    "The idea is to create steps that will help you make a good estimate of your error on data as it will come in real life. We've seen that:\n",
    "- if your model is too complex, it may memorize your training data (high variance)\n",
    "- if your model is too simple, you'll have performance problems (high bias)\n",
    "\n",
    "If your model memorizes your training data, you'll probably obtain a good performance score on your data, but when real data comes to you, you'll lose performance. We say that the model didn't `GENERALIZE` the patterns to unseen data. It means your error estimates were wrong. What can we do to avoid that?\n",
    "\n",
    "We can simulate what real life would look like. For example, one strategy is to hide some data from your model, to check its reliability on this never-seen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of the hold-out is to hide a part of the dataset and use it to test your model performance. The errors measured on your `Test set` will be a better estimate of the model performance in real life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important observation is that your model may be performing fairly well on your `Training Set`, but your `Test Set` performance may be poor. This may indicate your model is memorizing your data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several things that can be happening if you observe that your model is performing much better on the `Training data` than in your `Test data`.\n",
    "\n",
    "- Model is too complex\n",
    "    - solution: use a strategy to penalize model complexity if it doesn't bring much gain (regularization)\n",
    "    \n",
    "- Data Leakage\n",
    "    - you may be using some information that you shouldn't have in your training. Information from the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:06.018222Z",
     "start_time": "2022-03-19T12:55:05.988209Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_auto = pd.read_csv('data/tb_autompg.csv', na_values='?')\n",
    "tb_auto = tb_auto.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:06.326313Z",
     "start_time": "2022-03-19T12:55:06.307364Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_auto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:06.653527Z",
     "start_time": "2022-03-19T12:55:06.627596Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:07.086149Z",
     "start_time": "2022-03-19T12:55:07.069168Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_auto.columns = [col.replace(' ', '_') for col in tb_auto.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:15.295408Z",
     "start_time": "2022-03-19T12:55:08.025176Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(tb_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:15.326325Z",
     "start_time": "2022-03-19T12:55:15.297424Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_auto['log_weight'] = np.log(tb_auto['weight'])\n",
    "tb_auto['log_horsepower'] = np.log(tb_auto['horsepower'])\n",
    "tb_auto['log_displacement'] = np.log(tb_auto['displacement'])\n",
    "X_eda = tb_auto.drop(['mpg', 'car_name', 'weight', 'horsepower', 'displacement'], axis = 1)\n",
    "scaler = StandardScaler().fit(X_eda)\n",
    "pca_auto = PCA()\n",
    "pca_auto.fit(scaler.transform(X_eda))\n",
    "pca_eda = pca_auto.transform(scaler.transform(X_eda))\n",
    "tb_pca_eda = pd.DataFrame(pca_eda, columns = ['PC' + str(i) for i in range(pca_eda.shape[1])])\n",
    "tb_pca_eda['mpg'] = tb_auto['mpg']\n",
    "tb_pca_eda['log_mpg'] = np.log(tb_pca_eda['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.009430Z",
     "start_time": "2022-03-19T12:55:15.328324Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(tb_pca_eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout in Python\n",
    "\n",
    "Usually, people tend to separate approximately 20% of the dataset as a test (or holdout) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.025387Z",
     "start_time": "2022-03-19T12:55:25.011432Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tb_pca_eda.drop(['mpg', 'log_mpg'], axis = 1)\n",
    "y = tb_pca_eda['log_mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.041372Z",
     "start_time": "2022-03-19T12:55:25.027381Z"
    }
   },
   "outputs": [],
   "source": [
    "X['PC0_PC1'] = X['PC0'] * X['PC1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.072262Z",
     "start_time": "2022-03-19T12:55:25.043339Z"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar interações entre variáveis é um processo tedioso utilizando apenas a biblioteca pandas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.103207Z",
     "start_time": "2022-03-19T12:55:25.073259Z"
    }
   },
   "outputs": [],
   "source": [
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.119137Z",
     "start_time": "2022-03-19T12:55:25.107168Z"
    }
   },
   "outputs": [],
   "source": [
    "y, X = patsy.dmatrices('log_mpg ~ PC0 + PC1 + PC2', data = tb_pca_eda, return_type=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.135095Z",
     "start_time": "2022-03-19T12:55:25.121138Z"
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.151079Z",
     "start_time": "2022-03-19T12:55:25.137088Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.167009Z",
     "start_time": "2022-03-19T12:55:25.153045Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your error should be estimated using the `Test Set`. This will be a better estimate of your true error.\n",
    "\n",
    "Not only that, you should also calculate the error on your `Training Set` (called `training error`). This will be a good comparison to check whether your results on your `Test Set` (called `test error`) are getting too far from the results on your `Test Set`, which, again, can indicate an overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Leakage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.182965Z",
     "start_time": "2022-03-19T12:55:25.168007Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.198923Z",
     "start_time": "2022-03-19T12:55:25.183963Z"
    }
   },
   "outputs": [],
   "source": [
    "# R2 - correlação entre valores previstos e valores reais\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.214879Z",
     "start_time": "2022-03-19T12:55:25.200918Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_pred_leak = pd.DataFrame({'y_real' : np.exp(y_test['log_mpg'])})\n",
    "tb_pred_leak['pred'] = np.exp(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.402379Z",
     "start_time": "2022-03-19T12:55:25.216875Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = tb_pred_leak, x = 'pred', y = 'y_real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algumas medidas de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.417343Z",
     "start_time": "2022-03-19T12:55:25.403377Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_pred_leak['erro_pred'] = tb_pred_leak['y_real'] - tb_pred_leak['pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O RMSE é uma medida de erro equivalente ao desvio padrão dos resíduos, ou seja, ele mede o erro de previsão do modelo nas unidades da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.432298Z",
     "start_time": "2022-03-19T12:55:25.419333Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.sqrt(np.mean(tb_pred_leak['erro_pred'] ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.448258Z",
     "start_time": "2022-03-19T12:55:25.434295Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.464251Z",
     "start_time": "2022-03-19T12:55:25.450262Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(tb_pred_leak['y_real'], tb_pred_leak['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se a nossa variável resposta é positiva (Y > 0) então podemos calcular o erro médio percentual a partir do RMSPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.480171Z",
     "start_time": "2022-03-19T12:55:25.466209Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.sqrt(np.mean((tb_pred_leak['erro_pred']/tb_pred_leak['y_real']) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O MAPE é uma medida de erro muito utilizada em áreas que realizam previsões de demanda. Ele é semelhante ao RMSPE mas utiliza o valor absoluto (módulo) para corrigir erros negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.496156Z",
     "start_time": "2022-03-19T12:55:25.481173Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.mean(abs(tb_pred_leak['erro_pred'])/tb_pred_leak['y_real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.512130Z",
     "start_time": "2022-03-19T12:55:25.498123Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:25.528042Z",
     "start_time": "2022-03-19T12:55:25.515078Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(tb_pred_leak['y_real'], tb_pred_leak['pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's wrong with the process above?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: the EXACT same steps used to prepare your training data should be used on the new data \n",
    "\n",
    "\n",
    "So, you fit the standard scaler on your training data, and don't fit it again on your test data. Effectively, you'll be using the `mean` and `standard deviation` from the StandardScaler as you've seen on your training data (<b>pipelines</b> will soon come to rescue us for that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:41.935711Z",
     "start_time": "2022-03-19T12:55:41.926711Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pre = tb_auto.drop(['mpg', 'car_name'], axis = 1)\n",
    "y_pre = tb_auto['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:42.587746Z",
     "start_time": "2022-03-19T12:55:42.577745Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_pre, X_test_pre, y_train_pre, y_test_pre = train_test_split(X_pre, y_pre, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:43.608451Z",
     "start_time": "2022-03-19T12:55:43.575539Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_pre['log_weight'] = np.log(X_train_pre['weight'])\n",
    "X_train_pre['log_horsepower'] = np.log(X_train_pre['horsepower'])\n",
    "X_train_pre['log_displacement'] = np.log(X_train_pre['displacement'])\n",
    "X_train_pre = X_train_pre.drop(['weight', 'horsepower', 'displacement'], axis = 1).copy()\n",
    "X_train_pre.describe()\n",
    "scaler = StandardScaler().fit(X_train_pre)\n",
    "pca_auto = PCA()\n",
    "pca_auto.fit(scaler.transform(X_train_pre))\n",
    "pca_train = pca_auto.transform(scaler.transform(X_train_pre))\n",
    "tb_X_pca_train = pd.DataFrame(pca_train, columns = ['PC' + str(i) for i in range(pca_train.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:46.731436Z",
     "start_time": "2022-03-19T12:55:46.719454Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = patsy.dmatrix(' ~ PC0 + PC1 + PC2', data = tb_X_pca_train, return_type=\"dataframe\")\n",
    "y_train = np.log(y_train_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:47.368513Z",
     "start_time": "2022-03-19T12:55:47.358538Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:48.150913Z",
     "start_time": "2022-03-19T12:55:48.117812Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_pre['log_weight'] = np.log(X_test_pre['weight'])\n",
    "X_test_pre['log_horsepower'] = np.log(X_test_pre['horsepower'])\n",
    "X_test_pre['log_displacement'] = np.log(X_test_pre['displacement'])\n",
    "X_test_pre = X_test_pre.drop(['weight', 'horsepower', 'displacement'], axis = 1).copy()\n",
    "X_test_pre.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:51.983654Z",
     "start_time": "2022-03-19T12:55:51.976648Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_test = pca_auto.transform(scaler.transform(X_test_pre))\n",
    "tb_X_pca_test = pd.DataFrame(pca_test, columns = ['PC' + str(i) for i in range(pca_test.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:52.355044Z",
     "start_time": "2022-03-19T12:55:52.332903Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = patsy.dmatrix(' ~ PC0 + PC1 + PC2', data = tb_X_pca_test, return_type=\"dataframe\")\n",
    "y_test = np.log(y_test_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:55:53.113489Z",
     "start_time": "2022-03-19T12:55:53.106508Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_pred_test = pd.DataFrame({'y_real' : y_test_pre, 'pred' : np.exp(model.predict(X_test))})\n",
    "tb_pred_test['erro_pred'] = tb_pred_test['y_real'] - tb_pred_test['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:56:02.525423Z",
     "start_time": "2022-03-19T12:56:02.380716Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = tb_pred_test, x = 'pred', y = 'y_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-19T12:56:05.427124Z",
     "start_time": "2022-03-19T12:56:05.417151Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"RMSE: {np.sqrt(np.mean(tb_pred_test['erro_pred'] ** 2))}\")\n",
    "print(f\"RMSE: {np.sqrt(np.mean((tb_pred_leak['erro_pred']/tb_pred_leak['y_real']) ** 2))}\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
