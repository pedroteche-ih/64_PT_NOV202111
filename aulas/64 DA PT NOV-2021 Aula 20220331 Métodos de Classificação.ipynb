{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(point1, point2):\n",
    "    from math import atan2, cos, radians, sin, sqrt\n",
    "\n",
    "    R = 6370\n",
    "    lat1 = radians(point1[0])  # insert value\n",
    "    lon1 = radians(point1[1])\n",
    "    lat2 = radians(point2[0])\n",
    "    lon2 = radians(point2[1])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_atrasos = pd.read_csv(\"data/tb_atraso_olist.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_atrasos.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_limpeza = tb_atrasos.shape[0]\n",
    "tb_atrasos = tb_atrasos.dropna()\n",
    "print(f\"Num. linhas descartadas {pre_limpeza - tb_atrasos.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_atrasos[\"dist\"] = tb_atrasos.apply(\n",
    "    lambda x: get_distance(\n",
    "        (x[\"buyer_lat\"], x[\"buyer_long\"]), (x[\"seller_lat\"], x[\"seller_long\"])\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_atrasos[\"dt_compra\"] = pd.to_datetime(tb_atrasos[\"order_purchase_timestamp\"])\n",
    "tb_atrasos[\"dt_real\"] = pd.to_datetime(tb_atrasos[\"order_delivered_customer_date\"])\n",
    "tb_atrasos[\"dt_prevista\"] = pd.to_datetime(tb_atrasos[\"order_estimated_delivery_date\"])\n",
    "tb_atrasos[\"dias_previstos\"] = (\n",
    "    tb_atrasos[\"dt_prevista\"] - tb_atrasos[\"dt_compra\"]\n",
    ").dt.total_seconds() / (60 * 60 * 24)\n",
    "tb_atrasos[\"dias_atraso\"] = (\n",
    "    tb_atrasos[\"dt_real\"] - tb_atrasos[\"dt_prevista\"]\n",
    ").dt.total_seconds() / (60 * 60 * 24)\n",
    "tb_atrasos[\"atraso_bin\"] = np.where(tb_atrasos[\"dias_atraso\"] >= 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_atrasos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_atrasos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_atrasos.groupby(\"atraso_bin\")[[\"dist\", \"dias_previstos\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_atrasos[[\"dist\", \"dias_previstos\"]].quantile([0.05, 0.25, 0.5, 0.75, 0.95, 0.99, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q99_dist = np.quantile(tb_atrasos['dist'], 0.99)\n",
    "q99_dias = np.quantile(tb_atrasos['dias_previstos'], 0.99)\n",
    "mask_outlier = (tb_atrasos['dist'] < q99_dist) & (tb_atrasos['dias_previstos'] < q99_dias)\n",
    "tb_atrasos_nout = tb_atrasos[mask_outlier].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_atrasos_nout.shape[0] - tb_atrasos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(tb_atrasos[[\"dist\", \"dias_previstos\"]]), columns = [\"dist\", \"dias_previstos\"])\n",
    "y = tb_atrasos[\"atraso_bin\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que foi feito de errado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística (Modelo Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fit = LogisticRegression()\n",
    "log_fit.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(\n",
    "    np.array(X_train), np.array(y_train), log_fit, scatter_kwargs={\"alpha\": 1, \"s\": 1}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_dist = np.linspace(X_train[\"dist\"].min(), X_train[\"dist\"].max(), 200)\n",
    "vetor_peso = [X_train[\"dias_previstos\"].median()] * 200\n",
    "tb_simul_dist = pd.DataFrame({\"dist\": vetor_dist, \"dias_previstos\": vetor_peso})\n",
    "tb_simul_dist[\"prob_atraso_log\"] = log_fit.predict_proba(tb_simul_dist)[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_peso = np.linspace(\n",
    "    X_train[\"dias_previstos\"].min(), X_train[\"dias_previstos\"].max(), 200\n",
    ")\n",
    "vetor_dist = [X_train[\"dist\"].median()] * 200\n",
    "tb_simul_peso = pd.DataFrame({\"dist\": vetor_dist, \"dias_previstos\": vetor_peso})\n",
    "tb_simul_peso[\"prob_atraso_log\"] = log_fit.predict_proba(tb_simul_peso)[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.scatterplot(data=tb_simul_dist, x=\"dist\", y=\"prob_atraso_log\", ax=ax[0])\n",
    "sns.scatterplot(data=tb_simul_peso, x=\"dias_previstos\", y=\"prob_atraso_log\", ax=ax[1])\n",
    "ax[0].set_title(\"Impacto da Distância sobre Prob. Atraso\")\n",
    "ax[1].set_title(\"Impacto da Estimativa sobre Prob. Atraso\")\n",
    "fig.suptitle(\"Simulações usando Modelo Baseline (Reg. Log.)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = log_fit.predict(X_test)\n",
    "tb_p_test = pd.DataFrame({\"y_real\": y_test, \"pred_reglog\": pred_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Acurácia: {accuracy_score(tb_p_test['y_real'], tb_p_test['pred_reglog'])}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(tb_p_test['y_real'], tb_p_test['pred_reglog'])}\")\n",
    "print(f\"Precision: {precision_score(tb_p_test['y_real'], tb_p_test['pred_reglog'])}\")\n",
    "print(f\"Recall: {recall_score(tb_p_test['y_real'], tb_p_test['pred_reglog'])}\")\n",
    "print(f\"F1-Score: {f1_score(tb_p_test['y_real'], tb_p_test['pred_reglog'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train, log_fit.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_erros(nome_coluna_pred):\n",
    "    print(\n",
    "        f\"Acurácia: {accuracy_score(tb_p_test['y_real'], tb_p_test[nome_coluna_pred])}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"ROC-AUC Score: {roc_auc_score(tb_p_test['y_real'], tb_p_test[nome_coluna_pred])}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Precision: {precision_score(tb_p_test['y_real'], tb_p_test[nome_coluna_pred])}\"\n",
    "    )\n",
    "    print(f\"Recall: {recall_score(tb_p_test['y_real'], tb_p_test[nome_coluna_pred])}\")\n",
    "    print(f\"F1-Score: {f1_score(tb_p_test['y_real'], tb_p_test[nome_coluna_pred])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que aconteceu com o modelo de regressão? Como poderíamos melhora-lo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparâmetros\n",
    "* **n_neighbors** : Número de vizinhos\n",
    "* **weights** : Metodologia de ponderação dos vizinhos (devo penalizar vizinhos mais distantes?).\n",
    "* **metric** : Função de distância utilizada para 'escolher' vizinhos mais próximos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html#sklearn.metrics.DistanceMetric\n",
    "![title](metrica_distancia.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fit = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_fit.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(\n",
    "    np.array(X_train), np.array(y_train), knn_fit, scatter_kwargs={\"alpha\": 0, \"s\": 1}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_simul_dist.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_simul_dist[\"prob_atraso_knn\"] = knn_fit.predict_proba(\n",
    "    tb_simul_dist[[\"dist\", \"dias_previstos\"]]\n",
    ")[:, -1]\n",
    "tb_simul_peso[\"prob_atraso_knn\"] = knn_fit.predict_proba(\n",
    "    tb_simul_peso[[\"dist\", \"dias_previstos\"]]\n",
    ")[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.scatterplot(data=tb_simul_dist, x=\"dist\", y=\"prob_atraso_knn\", ax=ax[0])\n",
    "sns.scatterplot(data=tb_simul_dist, x=\"dist\", y=\"prob_atraso_log\", ax=ax[0])\n",
    "sns.scatterplot(data=tb_simul_peso, x=\"dias_previstos\", y=\"prob_atraso_knn\", ax=ax[1])\n",
    "sns.scatterplot(data=tb_simul_peso, x=\"dias_previstos\", y=\"prob_atraso_log\", ax=ax[1])\n",
    "ax[0].set_title(\"Impacto da Estimativa sobre Prob. Atraso\")\n",
    "ax[1].set_title(\"Impacto do Peso sobre Prob. Atraso\")\n",
    "fig.suptitle(\"Simulações usando Modelo Baseline (Reg. Log.)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_p_test[\"pred_knn\"] = knn_fit.predict(X_test)\n",
    "calcular_erros(\"pred_knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    knn_fit = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_fit.fit(X_train, y_train)\n",
    "    print(f\"{i}-NN F1 = {f1_score(y_test, knn_fit.predict(X_test))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 20):\n",
    "    knn_fit = KNeighborsClassifier(n_neighbors=i, weights=\"distance\")\n",
    "    knn_fit.fit(X_train, y_train)\n",
    "    print(f\"{i}-NN F1 = {f1_score(y_test, knn_fit.predict(X_test))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    \"n_neighbors\": range(1, 20),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"chebyshev\"],\n",
    "}\n",
    "knn_fit = KNeighborsClassifier()\n",
    "knn_opt = GridSearchCV(estimator=knn_fit, param_grid=parameter_grid, scoring=\"f1\",cv = 5)\n",
    "knn_opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(\n",
    "    np.array(X_train), np.array(y_train), knn_opt, scatter_kwargs={\"alpha\": 0, \"s\": 1}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_p_test[\"pred_knn\"] = knn_opt.predict(X_test)\n",
    "calcular_erros(\"pred_knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](svm.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/\n",
    "\n",
    "* **C**: parâmetro de regularização, **reduz o overfitting** do modelo simplificando a superficie de decisão\n",
    "* **kernel**: função utilizada para representar superficies não lineares\n",
    "* **gamma**: o quão *fechadas* as curvas do kernel podem ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svc = X_train[0:5000]\n",
    "y_train_svc = y_train[0:5000]\n",
    "svm_fit = SVC(class_weight = 'balanced')\n",
    "svm_fit.fit(X_train_svc, y_train_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(\n",
    "    np.array(X_train_svc), np.array(y_train_svc), svm_fit, scatter_kwargs={\"alpha\": 0, \"s\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_p_test[\"pred_svm\"] = svm_fit.predict(X_test)\n",
    "calcular_erros(\"pred_svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXERCICIO\n",
    "# MONTAR UM OTIMIZADOR DE HIPERPARAMETROS PARA O SVC ACIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvores de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n",
    "\n",
    "* **max_depth**: profundidade máxima da árvore\n",
    "* **min_samples_leaf**: número mínimo de amostras em cada nó final (folha) da árvore\n",
    "* **min_samples_split**: número mínimo de amostras em cada galho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit ingênuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fit = DecisionTreeClassifier()\n",
    "tree_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train, tree_fit.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, tree_fit.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que aconteceu??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduzindo Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devemos reduzir o overfitting de uma arvore de decisão utilizando os hiperparâmetros dela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fit = DecisionTreeClassifier(max_depth = 3, min_samples_leaf=0.25, class_weight = \"balanced\")\n",
    "tree_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(\n",
    "    np.array(X_train), np.array(y_train), tree_fit, scatter_kwargs={\"alpha\": 0, \"s\": 1}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 10))\n",
    "plot_tree(tree_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_simul_dist[\"prob_atraso_tree\"] = tree_fit.predict_proba(\n",
    "    tb_simul_dist[[\"dist\", \"dias_previstos\"]]\n",
    ")[:, -1]\n",
    "tb_simul_peso[\"prob_atraso_tree\"] = tree_fit.predict_proba(\n",
    "    tb_simul_peso[[\"dist\", \"dias_previstos\"]]\n",
    ")[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.scatterplot(data=tb_simul_dist, x=\"dist\", y=\"prob_atraso_tree\", ax=ax[0])\n",
    "sns.scatterplot(data=tb_simul_dist, x=\"dist\", y=\"prob_atraso_log\", ax=ax[0])\n",
    "sns.scatterplot(data=tb_simul_peso, x=\"dias_previstos\", y=\"prob_atraso_tree\", ax=ax[1])\n",
    "sns.scatterplot(data=tb_simul_peso, x=\"dias_previstos\", y=\"prob_atraso_log\", ax=ax[1])\n",
    "ax[0].set_title(\"Impacto da Distância sobre Prob. Atraso\")\n",
    "ax[1].set_title(\"Impacto da Estimativa sobre Prob. Atraso\")\n",
    "fig.suptitle(\"Simulações usando Modelo Baseline (Reg. Log.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_p_test[\"pred_tree\"] = tree_fit.predict(X_test)\n",
    "calcular_erros(\"pred_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(1, 50, 5)]\n",
    "min_samples_leaf = [int(x) for x in np.linspace(1, 20, 3)]\n",
    "min_samples_split = [int(x) for x in np.linspace(2, 40, 3)]\n",
    "parameter_grid = {\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"class_weight\": [\"balanced\", None] \n",
    "}\n",
    "tree_fit = DecisionTreeClassifier()\n",
    "tree_opt = GridSearchCV(estimator=tree_fit, param_grid=parameter_grid, scoring=\"f1\",cv = 5)\n",
    "tree_opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_p_test[\"pred_tree\"] = tree_opt.predict(X_test)\n",
    "calcular_erros(\"pred_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "![title](ensemble.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](rf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparâmetros\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "* **n_estimators**: número de arvores de decisão\n",
    "* **max_samples**: número de pontos em cada amostra\n",
    "\n",
    "\n",
    "Parâmetros do classificador bagged\n",
    "* **max_depth**: profundidade máxima da árvore (**CRITICO PARA ENSEMBLES!!**)\n",
    "* **min_samples_leaf**: número mínimo de amostras em cada nó final (folha) da árvore\n",
    "* **min_samples_split**: número mínimo de amostras em cada galho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fit = RandomForestClassifier(n_estimators = 1000, class_weight = \"balanced\", max_depth = 8)\n",
    "rf_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(\n",
    "    np.array(X_train), np.array(y_train), rf_fit, scatter_kwargs={\"alpha\": 0., \"s\": 1}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_p_test[\"rf_fit\"] = rf_fit.predict(X_test)\n",
    "calcular_erros(\"rf_fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fit = RandomForestClassifier(n_estimators = 10000, max_depth = 2, class_weight = \"balanced\")\n",
    "rf_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(\n",
    "    np.array(X_train), np.array(y_train), rf_fit, scatter_kwargs={\"alpha\": 0., \"s\": 1}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_p_test[\"rf_fit\"] = rf_fit.predict(X_test)\n",
    "calcular_erros(\"rf_fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/\n",
    "\n",
    "![title](boosting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparâmetros\n",
    "\n",
    "https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae\n",
    "\n",
    "* **learning_rate**: reduz a contribuição de cada modelo para reduzir overfitting\n",
    "* **n_estimator**: numero de modelos em séries\n",
    "\n",
    "Parâmetros do classificador boosted\n",
    "\n",
    "* **max_depth**: profundidade máxima da árvore (**CRITICO PARA ENSEMBLES!!**)\n",
    "* **min_samples_leaf**: número mínimo de amostras em cada nó final (folha) da árvore\n",
    "* **min_samples_split**: número mínimo de amostras em cada galho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_fit = GradientBoostingClassifier(n_estimators = 100, max_depth = 8)\n",
    "gb_fit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(\n",
    "    np.array(X_train), np.array(y_train), gb_fit, scatter_kwargs={\"alpha\": 0., \"s\": 1}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_p_test[\"pred_gb\"] = gb_fit.predict(X_test)\n",
    "calcular_erros(\"pred_gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = np.linspace(0.05, 0.8, 20)\n",
    "n_estimators = [int(x) for x in np.linspace(200, 1000, 20)]\n",
    "max_depth = range(1, 6)\n",
    "parameter_grid = {\n",
    "    \"max_depth\": max_depth,\n",
    "    \"n_estimators\" : n_estimators,\n",
    "    \"learning_rate\": learning_rate\n",
    "}\n",
    "gb_fit = GradientBoostingClassifier()\n",
    "gb_opt = RandomizedSearchCV(estimator=gb_fit, param_distributions=parameter_grid, scoring=\"f1\",cv = 5, n_iter = 5)\n",
    "gb_opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_opt.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "014f4a4a5af8f0104b12c029e500f4146d6d785e8cf714d2a35b7a9514230cd3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
